{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/MEDUSA_STOR/jprieto/surgery_tracking/csv/Labels_excel_json_output_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Video Name                                      Instrument Name           \n",
       "Cuff_Closure/Hyst_DPM_12.14.22e_3462_4190.mp4   Robot Needle Driver           21543\n",
       "                                                Robot Grasper                 21224\n",
       "                                                Needle                        17829\n",
       "Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4   Laparoscopic Needle Driver     8463\n",
       "Cuff_Closure/Hyst_BB_1.20.23a_3525_3753.mp4     Needle                         6227\n",
       "                                                Bipolar                        5464\n",
       "                                                Robot Needle Driver            5325\n",
       "Cuff_Closure/Hyst_DPM_12.14.22e_3462_4190.mp4   Vessel Sealer                  5066\n",
       "Cuff_Closure/Hyst_BB_4.17.23_3936_4064.mp4      Bipolar                        3836\n",
       "                                                Needle                         3819\n",
       "                                                Robot Needle Driver            3810\n",
       "Cuff_Closure/Hyst_BB_1.20.23a_3525_3753.mp4     Robot Grasper                  3414\n",
       "Cuff_Closure/Hyst_SurgU_3.21.23d_3069_3157.mp4  Laparoscopic Grasper           3104\n",
       "Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4   Needle                         2870\n",
       "Cuff_Closure/Hyst_SurgU_3.21.23d_3069_3157.mp4  Laparoscopic Needle Driver     1793\n",
       "                                                Needle                         1666\n",
       "Cuff_Closure/Hyst_BB_1.20.23a_3525_3753.mp4     Laparoscopic Grasper            320\n",
       "Cuff_Closure/!Hyst_MedT_3.20.23w_1604_1612.mp4  Laparoscopic Needle Driver      237\n",
       "                                                Laparoscopic Grasper            204\n",
       "Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4   Laparoscopic Grasper            106\n",
       "                                                Laparoscopic Scissors            80\n",
       "Cuff_Closure/!Hyst_MedT_3.20.23w_1604_1612.mp4  Needle                           31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Video Name','Instrument Name']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = '/MEDUSA_STOR/jprieto/surgery_tracking/csv/'\n",
    "\n",
    "# missing_vid = pd.read_csv('/MEDUSA_STOR/jprieto/surgery_tracking/csv/Hyst_SurgU_3.21.23a_cuff_closure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_train=['Hyst_BB_4.14.23_cuff_closure.csv', 'Hyst_BB_4.17.23_3630_3847.mp4_cuff_closure.csv', 'Hyst_JS_1.30.23_cuff_closure.csv', 'Hyst_SurgU_3.21.23d_3069_3157.mp4_cuff_closure.csv']\n",
    "# csv_test = [ 'Hyst_LHC_4.4.2023c_cuff_closure.csv', 'Hyst_SurgU_3.21.23b_cuff_closure.csv' , '!Hyst_MedT_3.21.23d_1219_1482.mp4_cuff_closure.csv']\n",
    "csv_val = [ 'Hyst_BB_1.20.23b_cuff_closure.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0         Dataset            Video Name   Frame  \\\n",
      "0           0  David Labeling  Hyst_BB_1.20.23b.mp4  123306   \n",
      "1           0  David Labeling  Hyst_BB_1.20.23b.mp4  123306   \n",
      "2           0  David Labeling  Hyst_BB_1.20.23b.mp4  123311   \n",
      "3           0  David Labeling  Hyst_BB_1.20.23b.mp4  123311   \n",
      "4           0  David Labeling  Hyst_BB_1.20.23b.mp4  123312   \n",
      "\n",
      "       Instrument Name         x         y         h         w  \\\n",
      "0  Robot Needle Driver  0.379986  0.099167  0.313333  0.311222   \n",
      "1   Robot Grasper Heat  0.088597  0.206042  0.271917  0.284306   \n",
      "2  Robot Needle Driver  0.378708  0.101104  0.313333  0.311208   \n",
      "3   Robot Grasper Heat  0.101431  0.195458  0.271917  0.284306   \n",
      "4  Robot Needle Driver  0.384569  0.096917  0.313333  0.311208   \n",
      "\n",
      "                                 img_path  class  \\\n",
      "0  img/Hyst_BB_1.20.23b_frame_123306.nrrd      5   \n",
      "1  img/Hyst_BB_1.20.23b_frame_123306.nrrd      8   \n",
      "2  img/Hyst_BB_1.20.23b_frame_123311.nrrd      5   \n",
      "3  img/Hyst_BB_1.20.23b_frame_123311.nrrd      8   \n",
      "4  img/Hyst_BB_1.20.23b_frame_123312.nrrd      5   \n",
      "\n",
      "                                            seg_path  \n",
      "0  bin_seg/Hyst_BB_1.20.23b_frame_123306_class_5_...  \n",
      "1  bin_seg/Hyst_BB_1.20.23b_frame_123306_class_8_...  \n",
      "2  bin_seg/Hyst_BB_1.20.23b_frame_123311_class_5_...  \n",
      "3  bin_seg/Hyst_BB_1.20.23b_frame_123311_class_8_...  \n",
      "4  bin_seg/Hyst_BB_1.20.23b_frame_123312_class_5_...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for csv in csv_val:\n",
    "  df_csv = pd.read_csv(os.path.join(csv_dir, csv))\n",
    "  print(df_csv.head())\n",
    "  df = pd.concat([df, df_csv])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('files_to_add_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instrument Name       class\n",
       "Robot Grasper Heat    8        1244\n",
       "Robot Needle Driver   5        1040\n",
       "Robot Grasper         6         553\n",
       "Laparoscopic Suction  10         48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Instrument Name', 'class']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_existing = pd.read_csv('/MEDUSA_STOR/jprieto/surgery_tracking/csv/dataset_6_classes_train_test.csv')\n",
    "df_existing = df_existing[['Dataset Title',\t'Video Name',\t'Frame', 'Instrument Name',\t'x',\t'y',\t'w',\t'h',\t'img_path',\t'seg_path',\t'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Dataset':'Dataset Title'})\n",
    "df = df[ ['Dataset Title',\t'Video Name',\t'Frame', 'Instrument Name',\t'x',\t'y',\t'w',\t'h',\t'img_path',\t'seg_path',\t'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_train = pd.concat([df, df_existing])\n",
    "# df_new_train.to_csv('dataset_train_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Title</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Instrument Name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>img_path</th>\n",
       "      <th>seg_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Labeling</td>\n",
       "      <td>Hyst_BB_1.20.23b.mp4</td>\n",
       "      <td>123306</td>\n",
       "      <td>Robot Needle Driver</td>\n",
       "      <td>0.379986</td>\n",
       "      <td>0.099167</td>\n",
       "      <td>0.311222</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>img/Hyst_BB_1.20.23b_frame_123306.nrrd</td>\n",
       "      <td>bin_seg/Hyst_BB_1.20.23b_frame_123306_class_5_...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Labeling</td>\n",
       "      <td>Hyst_BB_1.20.23b.mp4</td>\n",
       "      <td>123306</td>\n",
       "      <td>Robot Grasper Heat</td>\n",
       "      <td>0.088597</td>\n",
       "      <td>0.206042</td>\n",
       "      <td>0.284306</td>\n",
       "      <td>0.271917</td>\n",
       "      <td>img/Hyst_BB_1.20.23b_frame_123306.nrrd</td>\n",
       "      <td>bin_seg/Hyst_BB_1.20.23b_frame_123306_class_8_...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Labeling</td>\n",
       "      <td>Hyst_BB_1.20.23b.mp4</td>\n",
       "      <td>123311</td>\n",
       "      <td>Robot Needle Driver</td>\n",
       "      <td>0.378708</td>\n",
       "      <td>0.101104</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>img/Hyst_BB_1.20.23b_frame_123311.nrrd</td>\n",
       "      <td>bin_seg/Hyst_BB_1.20.23b_frame_123311_class_5_...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Labeling</td>\n",
       "      <td>Hyst_BB_1.20.23b.mp4</td>\n",
       "      <td>123311</td>\n",
       "      <td>Robot Grasper Heat</td>\n",
       "      <td>0.101431</td>\n",
       "      <td>0.195458</td>\n",
       "      <td>0.284306</td>\n",
       "      <td>0.271917</td>\n",
       "      <td>img/Hyst_BB_1.20.23b_frame_123311.nrrd</td>\n",
       "      <td>bin_seg/Hyst_BB_1.20.23b_frame_123311_class_8_...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Labeling</td>\n",
       "      <td>Hyst_BB_1.20.23b.mp4</td>\n",
       "      <td>123312</td>\n",
       "      <td>Robot Needle Driver</td>\n",
       "      <td>0.384569</td>\n",
       "      <td>0.096917</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>img/Hyst_BB_1.20.23b_frame_123312.nrrd</td>\n",
       "      <td>bin_seg/Hyst_BB_1.20.23b_frame_123312_class_5_...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>Encord_Clips_Cuff_Closure</td>\n",
       "      <td>Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4</td>\n",
       "      <td>6649</td>\n",
       "      <td>Needle</td>\n",
       "      <td>0.226852</td>\n",
       "      <td>0.364745</td>\n",
       "      <td>0.192159</td>\n",
       "      <td>0.442944</td>\n",
       "      <td>img/Hyst_MedT_3.20.23r_2965_3187_frame_6649.nrrd</td>\n",
       "      <td>bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_664...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>Encord_Clips_Cuff_Closure</td>\n",
       "      <td>Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4</td>\n",
       "      <td>6650</td>\n",
       "      <td>Needle</td>\n",
       "      <td>0.276872</td>\n",
       "      <td>0.276748</td>\n",
       "      <td>0.136091</td>\n",
       "      <td>0.330160</td>\n",
       "      <td>img/Hyst_MedT_3.20.23r_2965_3187_frame_6650.nrrd</td>\n",
       "      <td>bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_665...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>Encord_Clips_Cuff_Closure</td>\n",
       "      <td>Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4</td>\n",
       "      <td>6651</td>\n",
       "      <td>Needle</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.264393</td>\n",
       "      <td>0.164815</td>\n",
       "      <td>0.441353</td>\n",
       "      <td>img/Hyst_MedT_3.20.23r_2965_3187_frame_6651.nrrd</td>\n",
       "      <td>bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_665...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>Encord_Clips_Cuff_Closure</td>\n",
       "      <td>Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4</td>\n",
       "      <td>6652</td>\n",
       "      <td>Needle</td>\n",
       "      <td>0.247222</td>\n",
       "      <td>0.266864</td>\n",
       "      <td>0.221801</td>\n",
       "      <td>0.404289</td>\n",
       "      <td>img/Hyst_MedT_3.20.23r_2965_3187_frame_6652.nrrd</td>\n",
       "      <td>bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_665...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>Encord_Clips_Cuff_Closure</td>\n",
       "      <td>Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4</td>\n",
       "      <td>6653</td>\n",
       "      <td>Needle</td>\n",
       "      <td>0.246296</td>\n",
       "      <td>0.254510</td>\n",
       "      <td>0.207438</td>\n",
       "      <td>0.402644</td>\n",
       "      <td>img/Hyst_MedT_3.20.23r_2965_3187_frame_6653.nrrd</td>\n",
       "      <td>bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_665...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14404 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset Title  \\\n",
       "0                 David Labeling   \n",
       "1                 David Labeling   \n",
       "2                 David Labeling   \n",
       "3                 David Labeling   \n",
       "4                 David Labeling   \n",
       "...                          ...   \n",
       "11514  Encord_Clips_Cuff_Closure   \n",
       "11515  Encord_Clips_Cuff_Closure   \n",
       "11516  Encord_Clips_Cuff_Closure   \n",
       "11517  Encord_Clips_Cuff_Closure   \n",
       "11518  Encord_Clips_Cuff_Closure   \n",
       "\n",
       "                                          Video Name   Frame  \\\n",
       "0                               Hyst_BB_1.20.23b.mp4  123306   \n",
       "1                               Hyst_BB_1.20.23b.mp4  123306   \n",
       "2                               Hyst_BB_1.20.23b.mp4  123311   \n",
       "3                               Hyst_BB_1.20.23b.mp4  123311   \n",
       "4                               Hyst_BB_1.20.23b.mp4  123312   \n",
       "...                                              ...     ...   \n",
       "11514  Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4    6649   \n",
       "11515  Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4    6650   \n",
       "11516  Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4    6651   \n",
       "11517  Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4    6652   \n",
       "11518  Cuff_Closure/Hyst_MedT_3.20.23r_2965_3187.mp4    6653   \n",
       "\n",
       "           Instrument Name         x         y         w         h  \\\n",
       "0      Robot Needle Driver  0.379986  0.099167  0.311222  0.313333   \n",
       "1       Robot Grasper Heat  0.088597  0.206042  0.284306  0.271917   \n",
       "2      Robot Needle Driver  0.378708  0.101104  0.311208  0.313333   \n",
       "3       Robot Grasper Heat  0.101431  0.195458  0.284306  0.271917   \n",
       "4      Robot Needle Driver  0.384569  0.096917  0.311208  0.313333   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "11514               Needle  0.226852  0.364745  0.192159  0.442944   \n",
       "11515               Needle  0.276872  0.276748  0.136091  0.330160   \n",
       "11516               Needle  0.291700  0.264393  0.164815  0.441353   \n",
       "11517               Needle  0.247222  0.266864  0.221801  0.404289   \n",
       "11518               Needle  0.246296  0.254510  0.207438  0.402644   \n",
       "\n",
       "                                               img_path  \\\n",
       "0                img/Hyst_BB_1.20.23b_frame_123306.nrrd   \n",
       "1                img/Hyst_BB_1.20.23b_frame_123306.nrrd   \n",
       "2                img/Hyst_BB_1.20.23b_frame_123311.nrrd   \n",
       "3                img/Hyst_BB_1.20.23b_frame_123311.nrrd   \n",
       "4                img/Hyst_BB_1.20.23b_frame_123312.nrrd   \n",
       "...                                                 ...   \n",
       "11514  img/Hyst_MedT_3.20.23r_2965_3187_frame_6649.nrrd   \n",
       "11515  img/Hyst_MedT_3.20.23r_2965_3187_frame_6650.nrrd   \n",
       "11516  img/Hyst_MedT_3.20.23r_2965_3187_frame_6651.nrrd   \n",
       "11517  img/Hyst_MedT_3.20.23r_2965_3187_frame_6652.nrrd   \n",
       "11518  img/Hyst_MedT_3.20.23r_2965_3187_frame_6653.nrrd   \n",
       "\n",
       "                                                seg_path  class  \n",
       "0      bin_seg/Hyst_BB_1.20.23b_frame_123306_class_5_...      5  \n",
       "1      bin_seg/Hyst_BB_1.20.23b_frame_123306_class_8_...      8  \n",
       "2      bin_seg/Hyst_BB_1.20.23b_frame_123311_class_5_...      5  \n",
       "3      bin_seg/Hyst_BB_1.20.23b_frame_123311_class_8_...      8  \n",
       "4      bin_seg/Hyst_BB_1.20.23b_frame_123312_class_5_...      5  \n",
       "...                                                  ...    ...  \n",
       "11514  bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_664...      4  \n",
       "11515  bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_665...      4  \n",
       "11516  bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_665...      4  \n",
       "11517  bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_665...      4  \n",
       "11518  bin_seg/Hyst_MedT_3.20.23r_2965_3187_frame_665...      4  \n",
       "\n",
       "[14404 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_train.to_csv('dataset_train_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               img_path         class  Frame\n",
      "0            img/Hyst_BB_4.14.23_4219_5319_frame_1.nrrd  [1, 6, 5, 2]      1\n",
      "1         img/Hyst_BB_4.14.23_4219_5319_frame_1018.nrrd        [1, 5]   1018\n",
      "2         img/Hyst_BB_4.14.23_4219_5319_frame_1025.nrrd        [1, 5]   1025\n",
      "3         img/Hyst_BB_4.14.23_4219_5319_frame_1037.nrrd        [1, 5]   1037\n",
      "4         img/Hyst_BB_4.14.23_4219_5319_frame_1038.nrrd        [1, 5]   1038\n",
      "...                                                 ...           ...    ...\n",
      "28897  img/Hyst_SurgU_3.21.23d_3069_3157_frame_995.nrrd        [2, 3]    995\n",
      "28898  img/Hyst_SurgU_3.21.23d_3069_3157_frame_996.nrrd        [2, 3]    996\n",
      "28899  img/Hyst_SurgU_3.21.23d_3069_3157_frame_997.nrrd        [2, 3]    997\n",
      "28900  img/Hyst_SurgU_3.21.23d_3069_3157_frame_998.nrrd        [2, 3]    998\n",
      "28901  img/Hyst_SurgU_3.21.23d_3069_3157_frame_999.nrrd        [2, 3]    999\n",
      "\n",
      "[28902 rows x 3 columns]\n",
      "Frame distribution:\n",
      "Class 1: 9295 frames  (Target: 2492)\n",
      "Class 2: 2724 frames  (Target: 2492)\n",
      "Class 3: 2492 frames  (Target: 2492)\n",
      "Class 4: 23306 frames  (Target: 2492)\n",
      "Class 5: 25717 frames  (Target: 2492)\n",
      "Class 6: 21491 frames  (Target: 2492)\n",
      "\n",
      "Final frame distribution:\n",
      "Class 1: 2498 frames (Target: 2492)\n",
      "Class 2: 3558 frames (Target: 2492)\n",
      "Class 3: 2594 frames (Target: 2492)\n",
      "Class 4: 2742 frames (Target: 2492)\n",
      "Class 5: 2742 frames (Target: 2492)\n",
      "Class 6: 2110 frames (Target: 2492)\n",
      "\n",
      "Total frames selected: 5452\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def select_balanced_frames(df, target_per_class=None, max_deviation=0.2):\n",
    "    \"\"\"\n",
    "        Create a balanced dataframe with similar number of frames per instrument class. The frames selected will \n",
    "        have all their instruments listed/counted. Thus, we can't just drop randoms frames or instruments.\n",
    "        \n",
    "        target_per_class: number of frames per class, if set to None, take the minimun of frames found per class\n",
    "        max_deviation: to ensure flexibility, we allow the dataframe to be slightly unbalanced, (i.e 0.2 -> 20%)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Group by img_path to get unique frames and their class composition\n",
    "    frames_info = df.groupby('img_path').agg({\n",
    "        'class': list,\n",
    "        'Frame': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Count initial class distribution -> to know how many frames exists per instruments\n",
    "    initial_class_counts = defaultdict(int)\n",
    "    for classes in frames_info['class']:\n",
    "        # Use set to count unique classes per frame\n",
    "        for cls in set(classes):\n",
    "            initial_class_counts[cls] += 1\n",
    "    \n",
    "    # attention: target_per_class is the number of frames we want. So even if we are selecting the frame of the \n",
    "    # smallest class (i.e. class 3 - 2594 instrument ) it might be a smaller number (we get 2492). This is normal:\n",
    "    # we can have 2 instruments of class 3 in the same frame. That's why the number of frame is < intrument count.\n",
    "\n",
    "    if target_per_class is None:\n",
    "        target_per_class = min(initial_class_counts.values())\n",
    "    \n",
    "    target_class_frames = {}\n",
    "    for cls, count in initial_class_counts.items():\n",
    "        # take the smallest amount of frames avalaible or how many we want\n",
    "        target_class_frames[cls] = min(count, target_per_class)\n",
    "\n",
    "    print(\"Frame distribution:\")\n",
    "    for cls, count in sorted(initial_class_counts.items()):\n",
    "        print(f\"Class {cls}: {count} frames  (Target: {target_class_frames[cls]})\")\n",
    "    \n",
    "\n",
    "    # Shuffle frames \n",
    "    frames_info = frames_info.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    selected_frames = set()\n",
    "    class_frame_counts = defaultdict(int)\n",
    "    \n",
    "\n",
    "    # Need to fill the dataframe by the smallest classes to ensure we use all the frames available\n",
    "    # Without it if target per class = 106 (class 3), if the instrument is on a frame with other \n",
    "    # instrument, they are not going to be selected and class 3 ends up with 65 frames < target_per_class\n",
    "\n",
    "    sorted_classes = sorted(initial_class_counts.keys(), key=lambda x: initial_class_counts[x])\n",
    "    for cls in sorted_classes:\n",
    "        for _, row in frames_info.iterrows():\n",
    "            # If frame has been selected before, skip\n",
    "            if row['img_path'] in selected_frames:\n",
    "                continue\n",
    "            \n",
    "            if cls in row['class']:\n",
    "                # Check if adding this frame would exceed the number of frame we want\n",
    "                would_exceed = False\n",
    "                for frame_cls in set(row['class']):\n",
    "                    if class_frame_counts[frame_cls] >= target_per_class*(1 + max_deviation) :\n",
    "                        would_exceed = True\n",
    "                        break\n",
    "                \n",
    "                \n",
    "                if not would_exceed:\n",
    "                    selected_frames.add(row['img_path'])\n",
    "                    for frame_cls in set(row['class']):\n",
    "                        class_frame_counts[frame_cls] += 1\n",
    "            \n",
    "            # if we have enough frame in the class\n",
    "            if class_frame_counts[cls] >= target_per_class:\n",
    "                break\n",
    "        \n",
    "    selected_df = df[df['img_path'].isin(selected_frames)].copy()\n",
    "    \n",
    "    print(\"\\nFinal frame distribution:\")\n",
    "    for cls in sorted(initial_class_counts.keys()):\n",
    "        count = sum(1 for _, row in selected_df.iterrows() if row['class'] == cls)\n",
    "        target = target_class_frames[cls]\n",
    "        print(f\"Class {cls}: {count} frames (Target: {target})\")\n",
    "    \n",
    "    print(f\"\\nTotal frames selected: {len(selected_frames)}\")\n",
    "    \n",
    "    return selected_df\n",
    "\n",
    "# Select balanced frames\n",
    "balanced_df = select_balanced_frames(df, target_per_class=None, max_deviation=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    25717\n",
       "4    23314\n",
       "6    21491\n",
       "1     9307\n",
       "2     3789\n",
       "3     2594\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_frame_compositions(df):\n",
    "    \"\"\"Analyze how classes appear together in frames\"\"\"\n",
    "    frame_compositions = defaultdict(list)\n",
    "    class_cooccurrence = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for _, group in df.groupby('img_path'):\n",
    "        classes = sorted(group['class'].unique())\n",
    "        frame_compositions[tuple(classes)].append(group['img_path'].iloc[0])\n",
    "        \n",
    "        # Count how often each class appears with other classes\n",
    "        for c1 in classes:\n",
    "            for c2 in classes:\n",
    "                if c1 != c2:\n",
    "                    class_cooccurrence[c1][c2] += 1\n",
    "    \n",
    "    print(\"\\nFrame composition analysis:\")\n",
    "    for classes, frames in frame_compositions.items():\n",
    "        print(f\"Classes {classes}: {len(frames)} frames\")\n",
    "        \n",
    "    return frame_compositions, class_cooccurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frame composition analysis:\n",
      "Classes (1, 5): 649 frames\n",
      "Classes (1,): 181 frames\n",
      "Classes (1, 5, 6): 243 frames\n",
      "Classes (1, 6): 183 frames\n",
      "Classes (6,): 58 frames\n",
      "Classes (5,): 79 frames\n",
      "Classes (5, 6): 69 frames\n",
      "Classes (3, 4): 2609 frames\n",
      "Classes (3,): 3068 frames\n",
      "Classes (4,): 250 frames\n",
      "Classes (2, 3, 4): 1 frames\n",
      "Classes (2, 3): 41 frames\n",
      "Classes (2,): 64 frames\n",
      "Classes (1, 3): 80 frames\n"
     ]
    }
   ],
   "source": [
    "frame_compositions, class_cooccurrence=analyze_frame_compositions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {5: 1040, 1: 1372, 6: 553, 4: 2870, 3: 8463, 2: 106})\n",
      "106\n",
      "{5: 9.81132075471698, 1: 12.943396226415095, 6: 5.216981132075472, 4: 27.07547169811321, 3: 79.83962264150944, 2: 1.0}\n",
      "[(1.0, (2,)), (1.0, (2, 3)), (1.0, (2, 3, 4)), (5.216981132075472, (1, 5, 6)), (5.216981132075472, (1, 6)), (5.216981132075472, (5, 6)), (5.216981132075472, (6,)), (9.81132075471698, (1, 5)), (9.81132075471698, (5,)), (12.943396226415095, (1,)), (12.943396226415095, (1, 3)), (27.07547169811321, (3, 4)), (27.07547169811321, (4,)), (79.83962264150944, (3,))]\n",
      "64\n",
      "41\n",
      "1\n",
      "243\n",
      "183\n",
      "69\n",
      "58\n",
      "649\n",
      "79\n",
      "181\n",
      "80\n",
      "2609\n",
      "250\n",
      "3068\n",
      "\n",
      "Class distribution in selected frames:\n",
      "Class 1: 0 instances\n",
      "Class 2: 106 instances\n",
      "Class 3: 56 instances\n",
      "Class 4: 12 instances\n",
      "Class 5: 159 instances\n",
      "Class 6: 159 instances\n",
      "\n",
      "Total frames selected: 277\n"
     ]
    }
   ],
   "source": [
    "frames_instruments = df.groupby('img_path').agg({\n",
    "    'class': list,\n",
    "    'Frame': 'first'  # We need frame number for reference\n",
    "}).reset_index()\n",
    "    \n",
    "# Count how many times each class appears in each frame\n",
    "frame_class_counts = defaultdict(lambda: defaultdict(int))\n",
    "for idx, row in frames_instruments.iterrows():\n",
    "    for class_num in row['class']:\n",
    "        frame_class_counts[row['img_path']][class_num] += 1\n",
    "    \n",
    "# Count total instances of each class in the dataset\n",
    "total_class_counts = defaultdict(int)\n",
    "for frame_path, class_counts in frame_class_counts.items():\n",
    "    for class_num, count in class_counts.items():\n",
    "        total_class_counts[class_num] += count\n",
    "\n",
    "\n",
    "print(total_class_counts)\n",
    "# # If target_per_class is not specified, use the minimum class count\n",
    "# target_per_class = 10\n",
    "target_per_class= None\n",
    "if target_per_class is None:\n",
    "    target_per_class = min(total_class_counts.values())\n",
    "\n",
    "# # Initialize selection tracking\n",
    "selected_frames = set()\n",
    "current_counts = defaultdict(int)\n",
    "frames_by_composition = defaultdict(list)\n",
    "for frame, classes in frame_class_counts.items():\n",
    "    frames_by_composition[tuple(sorted(classes.keys()))].append(frame)\n",
    "\n",
    "# Prioritize frames with underrepresented classes\n",
    "class_ratios = {cls: total_class_counts[cls] / target_per_class \n",
    "                for cls in total_class_counts}\n",
    "print(class_ratios)\n",
    "# Sort class combinations by priority (presence of underrepresented classes)\n",
    "composition_priority = []\n",
    "for composition, frames in frames_by_composition.items():\n",
    "    priority = min(class_ratios[cls] for cls in composition)\n",
    "    composition_priority.append((priority, composition))\n",
    "\n",
    "composition_priority.sort()  # Sort by priority (lower ratio = higher priority)\n",
    "\n",
    "print(composition_priority)\n",
    "\n",
    "# Select frames prioritizing underrepresented classes\n",
    "for _, composition in composition_priority:\n",
    "    available_frames = frames_by_composition[composition]\n",
    "    random.shuffle(available_frames)\n",
    "\n",
    "    print(len(available_frames))\n",
    "    \n",
    "    for frame in available_frames:\n",
    "        frame_classes = frame_class_counts[frame]\n",
    "        \n",
    "        # Check if adding this frame would exceed target for any class\n",
    "        would_exceed = False\n",
    "        for class_num, count in frame_classes.items():\n",
    "            if current_counts[class_num] + count > target_per_class *1.5:\n",
    "\n",
    "                would_exceed = True\n",
    "                break\n",
    "        \n",
    "        if not would_exceed:\n",
    "            selected_frames.add(frame)\n",
    "            for class_num, count in frame_classes.items():\n",
    "                current_counts[class_num] += count\n",
    "        \n",
    "        # Check if we have reached minimum targets for all classes\n",
    "        all_classes_met = True\n",
    "        for class_num in total_class_counts.keys():\n",
    "            if current_counts[class_num] < target_per_class *0.1:\n",
    "                all_classes_met = False\n",
    "                break\n",
    "        \n",
    "        if all_classes_met:\n",
    "            break\n",
    "\n",
    "# Create final dataset with selected frames\n",
    "selected_df = df[df['img_path'].isin(selected_frames)].copy()\n",
    "\n",
    "print(\"\\nClass distribution in selected frames:\")\n",
    "for class_num in sorted(total_class_counts.keys()):\n",
    "    count = sum(1 for _, row in selected_df.iterrows() if row['class_column'] == class_num)\n",
    "    print(f\"Class {class_num}: {count} instances\")\n",
    "\n",
    "print(f\"\\nTotal frames selected: {len(selected_frames)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 9307, 6: 21491, 5: 25717, 2: 3789, 4: 23314, 3: 2594})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_frames = df['img_path'].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toDrop'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in list_frames:\n",
    "\n",
    "  df_frame = df.loc[df['img_path']==frame]\n",
    "\n",
    "  classes = df_frame['class'].to_list()\n",
    "\n",
    "  for elt in classes:\n",
    "    if elt in [2,3]:\n",
    "      df.loc[df_frame.index, 'toDrop'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toDrop  class\n",
       "1       5        25692\n",
       "        4        21648\n",
       "        6        21466\n",
       "        1         9270\n",
       "0       2         3789\n",
       "        3         2594\n",
       "        4         1666\n",
       "        1           37\n",
       "        5           25\n",
       "        6           25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['toDrop', 'class']].sort_values(by='toDrop').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kept = df.loc[df['toDrop']==0]\n",
    "df_todrop = df.loc[df['toDrop']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3789\n",
       "3    2594\n",
       "4    1666\n",
       "1      37\n",
       "6      25\n",
       "5      25\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kept['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    25692\n",
       "4    21648\n",
       "6    21466\n",
       "1     9270\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_todrop['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    25692\n",
       "4    21648\n",
       "6    21466\n",
       "1     9270\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_todrop['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_todrop.groupby('img_path').sample(n=1)\n",
    "# train = df_todrop.groupby('img_path').apply(lambda x : x.sample(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    8884\n",
       "4    7089\n",
       "6    7076\n",
       "1    2989\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_todrop.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    8358\n",
       "6    7241\n",
       "4    7045\n",
       "1    2826\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['class'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flyby",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
